{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Activity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Load the required file from AWS s3 as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start up spark and sql context for dataframes!\n",
    "sc = SparkContext('local','WordCountApp')\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = '686springbucket-emmanuel'\n",
    "my_key1 = 'movie_magic/movie_characters_metadata.csv'\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from s3fs.core import S3FileSystem\n",
    "\n",
    "#this is a bit convoluted b/c we are using s3 but...\n",
    "#first we read the data into pandas\n",
    "\n",
    "s3 = S3FileSystem(anon=False)\n",
    "df1 = pd.read_csv(s3.open('{}/{}'.format(my_bucket, my_key1), mode='rb'))\n",
    "\n",
    "my_key2 = 'movie_magic/movie_titles_metadata.csv'\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from s3fs.core import S3FileSystem\n",
    "\n",
    "#this is a bit convoluted b/c we are using s3 but...\n",
    "#first we read the data into pandas\n",
    "\n",
    "df2 = pd.read_csv(s3.open('{}/{}'.format(my_bucket, my_key2), mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Load the movie_titles_metadata csv as a pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now we convert to a \"pyspark\" dataframe which is distributed using\n",
    "#our sqlContext, we also use a struct to make sure all the \n",
    "#columns have the names we want and the types (sometimes the conversion from\n",
    "#pandas to dataframe gets messed up b/c of type issues)\n",
    "movieSchema1 = StructType([StructField(\"character_id\", StringType(), False), \\\n",
    "                      StructField(\"character_name\", StringType(), False),\\\n",
    "                      StructField(\"movie_id\", StringType(), False),\\\n",
    "                      StructField(\"movie_name\", StringType(), False),\\\n",
    "                      StructField(\"character_gender\", StringType(), False),\\\n",
    "                      StructField(\"position_in_credits\", StringType(), False)])\n",
    "\n",
    "movieSchema2 = StructType([StructField(\"movie_id\", StringType(), True), \\\n",
    "                      StructField(\"movie_title\", StringType(), True),\\\n",
    "                      StructField(\"movie_year\", StringType(), True),\\\n",
    "                      StructField(\"IMDB_rating\", DoubleType(), True),\\\n",
    "                      StructField(\"IMDB_votes\", LongType(), True),\\\n",
    "                      StructField(\"genres\", StringType(), True)])\n",
    "\n",
    "pyDF1 = sqlContext.createDataFrame(df1,schema=movieSchema1)\n",
    "pyDF2 = sqlContext.createDataFrame(df2,schema=movieSchema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- character_id: string (nullable = false)\n",
      " |-- character_name: string (nullable = false)\n",
      " |-- movie_id: string (nullable = false)\n",
      " |-- movie_name: string (nullable = false)\n",
      " |-- character_gender: string (nullable = false)\n",
      " |-- position_in_credits: string (nullable = false)\n",
      "\n",
      "+------------+--------------+--------+--------------------+----------------+-------------------+\n",
      "|character_id|character_name|movie_id|          movie_name|character_gender|position_in_credits|\n",
      "+------------+--------------+--------+--------------------+----------------+-------------------+\n",
      "|          u0|        BIANCA|      m0|10 things i hate ...|               f|                  4|\n",
      "|          u1|         BRUCE|      m0|10 things i hate ...|               ?|                  ?|\n",
      "|          u2|       CAMERON|      m0|10 things i hate ...|               m|                  3|\n",
      "|          u3|      CHASTITY|      m0|10 things i hate ...|               ?|                  ?|\n",
      "|          u4|          JOEY|      m0|10 things i hate ...|               m|                  6|\n",
      "+------------+--------------+--------+--------------------+----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- movie_title: string (nullable = true)\n",
      " |-- movie_year: string (nullable = true)\n",
      " |-- IMDB_rating: double (nullable = true)\n",
      " |-- IMDB_votes: long (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+--------+--------------------+----------+-----------+----------+--------------------+\n",
      "|movie_id|         movie_title|movie_year|IMDB_rating|IMDB_votes|              genres|\n",
      "+--------+--------------------+----------+-----------+----------+--------------------+\n",
      "|      m0|10 things i hate ...|      1999|        6.9|     62847|['comedy'COMMA 'r...|\n",
      "|      m1|1492: conquest of...|      1992|        6.2|     10421|['adventure'COMMA...|\n",
      "|      m2|          15 minutes|      2001|        6.1|     25854|['action'COMMA 'c...|\n",
      "|      m3|2001: a space ody...|      1968|        8.4|    163227|['adventure'COMMA...|\n",
      "|      m4|             48 hrs.|      1982|        6.9|     22289|['action'COMMA 'c...|\n",
      "+--------+--------------------+----------+-----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#look at our schema to make sure everything read well\n",
    "pyDF1.printSchema()\n",
    "pyDF1.show(5)\n",
    "pyDF2.printSchema()\n",
    "pyDF2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Now use the withColumn transformation to create a new column called IMDB_Movie_Avg which will be the IMDB_rating / IMDB_votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyDF2 = pyDF2.withColumn('IMDB_Avg_Rating',pyDF2['IMDB_rating'] / pyDF2['IMDB_votes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Next, filter the pyDFTitle dataframe so that it only contains movies distributed after 1990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyDF2_after1990 = pyDF2.filter(pyDF2['movie_year']>'1990')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Join the pyDFTitle (that has movie information) and pyDF dataframes (which has character id) by movie_id (examples in slides).  Just use the default join type. Save the resulting dataframe in a dataframe called pyDFCharMovie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyDFCharMovie = pyDF1.join(pyDF2_after1990,pyDF1.movie_id == pyDF2_after1990.movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Order the pyDFCharMovie by movie_year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyDFCharMovie = pyDFCharMovie.orderBy('movie_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. Finally, write out your csv file to s3. **Note:** The fused_data.csv has also been uploaded in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_to_write = pyDFCharMovie.toPandas().to_csv(None).encode()\n",
    "with s3.open('s3://686springbucket-emmanuel/movie_magic/fused_data.csv', 'wb') as f:\n",
    "   \tf.write(bytes_to_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
